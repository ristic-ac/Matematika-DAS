\section{Увод}
Интерпретабилност модела у задацима класификације постаје све важнија, како би се одлуке система могле проверити и применити у окружењима са ограничењима поузданости и одговорности. Дестилација сложених учитељских модела у логичка правила представља један од практичних приступа, јер се добија компактна репрезентација која омогућава анализу услова доношења одлуке без ослањања на комплексне нумеричке параметре. У овом раду се испитује дестилација у оквиру ИЛП система \emph{Aleph}, при чему се фокус усмерава на однос између верности учитељу (фиделитета) и стварне тачности према истинитим ознакама, као и на утицај сложености индукованих правила на квалитет и разумљивост модела. Процес обухвата претпроцесирање података (дискретизацију нумеричких атрибута и балансирање класа \emph{undersampling}-ом), обуку учитељских модела \emph{DT}, \emph{RF} и \emph{XGB} са претрагом хиперпараметара путем \emph{grid search} и унакрсне валидације, као и дестилацију у три пресета, односно поставке (\textit{sniper}, \textit{sweet\_spot}, \textit{sweeper}), које покривају различите компромисе између прецизности, покривености и сложености. Евалуација се спроводи на скуповима \emph{Mushroom} и \emph{Adult} са \emph{OpenML}-а, уз процену метрика \emph{accuracy}, \emph{precision}, \emph{recall}, \emph{F1}, \emph{MCC} и фиделитета, како би се квантификовао ефекат пресета и избора учитеља на добијене дестилате. Циљ је да се идентификује зона компромиса у којој се постижу стабилне метрике уз мали број правила и умерену дужину тела клаузе, што омогућава практичну примену са јасним објашњењима.