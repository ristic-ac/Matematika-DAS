\section{Теоријски основи}

У овом поглављу су представљени основни појмови из логике, машинског учења и индуктивног логичког програмирања, који су неопходни за разумевање даљег текста.

\subsection{Увод у логику}
Логика је формални систем за прецизно представљање знања и извођење закључака на основу правила и чињеница. У вештачкој интелигенцији логика обезбеђује недвосмислен и објашњив језик за описивање релација између објеката и догађаја: сваки закључак може да се прати уназад до правила и претпоставки из којих је произашао.

\medskip
\noindent\textbf{Три аспекта логике.} Разликују се: (1) \emph{синтакса} (који су исправни изрази/формуле), (2) \emph{семантика} (шта ти изрази значе и када су истинити), и (3) \emph{дедуктивни системи} (правила за извођење доказа). \cite{janii_2004_matematika}.

\subsection{Исказна логика}
\emph{Искази} су тврдње са вредностима \emph{истинито}/\emph{неистинито}. Основни симболи су исказна слова ($p,q,r,\ldots$), а сложени искази се граде логичким везницима: негација ($\neg$), конјункција ($\land$), дисјункција ($\lor$), импликација ($\rightarrow$) и еквиваленција ($\leftrightarrow$). \cite{janii_2004_matematika}.

\paragraph{Пример.} Ако је $p$ „Данас је сунчано“, а $q$ „Идем на излет“, онда $p\land q$ значи „Данас је сунчано \emph{и} идем на излет“.

\subsection{Логика првог реда}
Логика првог реда проширује исказну увођењем \emph{предиката} (нпр. $Student(x)$: „$x$ је студент“), \emph{функција} (нпр. $father(x)$: „отац од $x$“), \emph{константи} (нпр. $john$: „Јован“), и \emph{квантификатора} (нпр. $\forall x\,Human(x)$: „сви су људи“; $\exists x\,Student(x)$: „постоји студент“). Универзални квантификатор ($\forall$) значи „за свако“, а егзистенцијални ($\exists$) „постоји“.

\paragraph{Пример формализације.} „Сваки студент воли да полаже испит“ можемо записати као
\[
\forall x\,\big(S(x)\rightarrow L(x)\big),
\]
где $S(x)$ значи „$x$ је студент“, а $L(x)$ „$x$ воли да полаже испит“.

\subsection{Термови}
\textbf{Терм} је основна синтаксичка јединица логике првог реда која представља објекат у домену. 
Термови се граде рекурзивно према следећим правилима:
\begin{enumerate}
  \item Свака \textbf{константа} је терм (нпр. $a$, $john$, $0$).
  \item Свака \textbf{променљива} је терм (нпр. $X$, $Y$, $Z$).
  \item Ако је $f$ функцијски симбол арности $n$, а $t_1,\dots,t_n$ термови, онда је и\\
  \(
  f(t_1, t_2, \dots, t_n)
  \)
  терм.
\end{enumerate}
\noindent На овај начин добијамо \emph{једноставне термове} (константе, променљиве) и \emph{сложене термове} (изграђене помоћу функцијских симбола). \cite{janii_2004_matematika}.

\paragraph{Атоми и формуле.}
\emph{Атом} је предикат примењен на термове, нпр. $P(t_1,\dots,t_n)$. \emph{Формуле} се граде од атома логичким везницима и квантификаторима. \emph{Базни} (ground) терм/атом нема променљиве. \cite{janii_2004_matematika}.

\paragraph{Примери.}
\begin{itemize}
  \item $7$ је терм (константа).  
  \item $X$ је терм (променљива).  
  \item $father(john)$ је терм (функција над једним аргументом).  
  \item $point(X,3)$ је сложен терм.  
  \item $parent(john,mary)$ је \emph{атом}; његови аргументи су термови $john$ и $mary$.
\end{itemize}

\subsection{Закључивање у логици}
\begin{itemize}
  \item Дедукција: од општих премиса ка појединачним закључцима (нужно важење).
  \item Абдукција: проналажење најбољег објашњења за уочене податке (за формирање хипотеза). \cite{janii_2004_matematika}
  \item \textbf{Индукција:} од примера ка општим правилима (није нужно тачна, али је кључна за учење).
\end{itemize}

\subsection{Клаузе и нормалне форме}
\textbf{Литерал} је атомска формула или њена негација. \textbf{Клауза} је дисјункција литерала (нпр. $\neg p\lor q\lor r$). \emph{Конјунктивна нормална форма} (КНФ) је конјункција клаузa; \emph{Дисјунктивна нормална форма} (ДНФ) је дисјункција конјункција литерала. \cite{janii_2004_matematika}.

Клауза без литерала је \emph{празна клауза} и означава се $\Box$. Она је \emph{незадовољива}; појављивање $\Box$ у доказу значи контрадикцију.

\subsection{Хорнове клаузе}
\textbf{Хорнова клауза} је клауза са највише \emph{једним позитивним} (без негације) литералом. Типични облици се приказују у табели \ref{table:horn_clauses}.
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Тип} & \textbf{Импликациона форма} & \textbf{Клаузална форма} & \textbf{Prolog} \\
\midrule
Правило (импликационо) & $A_1\land\cdots\land A_n\;\rightarrow\; A$ & $\neg A_1 \vee\cdots\vee \neg A_n \vee A$ & \texttt{A :- A1, ..., An.} \\
Циљ (упит) & $A_1\land\cdots\land A_n\;\rightarrow\; \bot$ & $\neg A_1 \vee\cdots\vee \neg A_n$ & \texttt{?- A1, ..., An.} \\
Чињеница & $\top\;\rightarrow\; A$ & $A$ & \texttt{A.} \\
Празна клауза & $\top\;\rightarrow\; \bot$ & $\Box$ & \texttt{false.} \\
\bottomrule
\end{tabular}
}
\caption{Облици Хорнових клауза.}
\label{table:horn_clauses}
\end{table}
\noindent Општа резолуција се специјализује на Хорнове клаузе у облику процедуралног, ефикаснијег система заснованог на \emph{избору потциља} и \emph{линеарним} деривацијама (в.\ SLD испод). \cite{janii_2004_matematika}.

\subsection{Клаузна форма}

Претварање формула у клаузну форму је кључни корак у аутоматском закључивању. Процес укључује стандардне трансформације логичких формула.

\paragraph{Пример претварања.}
Формула „Сваки студент који похађа наставу је учесник" записује се као
\[
\forall x\,\big(Student(x) \land Attends(x) \rightarrow Participant(x)\big).
\]

\paragraph{Кораци претварања:}
\begin{enumerate}
  \item \textbf{Елиминација импликације:} $P \rightarrow Q$ се претвара у $\neg P \lor Q$. 
  
  Где је $P = Student(x) \land Attends(x)$ и $Q = Participant(x)$:
  \[
  \neg\big(Student(x) \land Attends(x)\big) \lor Participant(x)
  \]
  
  \item \textbf{Примена де Моргановог закона:} $\neg(A \land B) = \neg A \lor \neg B$:
  \[
  \neg Student(x) \lor \neg Attends(x) \lor Participant(x)
  \]
\end{enumerate}

\paragraph{Резултат.}
Добијена клауза има облик „или није студент, или не похађа наставу, или је учесник". То је Хорнова клауза са једним позитивним литералом $Participant(x)$ и два негативна $\neg Student(x)$ и $\neg Attends(x)$.

\subsection{Унификација и SLD резолуција}

\subsubsection{Унификација}
Нека су $t_1$ и $t_2$ термови. \textbf{Унификација} је поступак тражења супституције $\theta$ такве да важи
\[
t_1 \theta = t_2 \theta.
\]
Ако таква супституција постоји, термови су \emph{унификативни}, а $\theta$ је \emph{унификатор}.

\paragraph{Најопштији унификатор (\textit{MGU - most general unifier}).}
Ако $t_1$ и $t_2$ имају унификатор, постоји \emph{најопштији унификатор} $\sigma$ такав да се сваки други унификатор $\theta$ може написати као $\theta = \delta \circ \sigma$ за неку супституцију $\delta$. (Интуитивно: $\sigma$ не везује „више него што мора“.) 

\subsubsection{SLD резолуција}
Нека је $P$ скуп коначних Хорнових клауза, где свака клауза има облик
\[
H \; :- \; B_1, B_2, \dots, B_m
\]
са главом $H$ и телом $B_1, \dots, B_m$. Нека је почетни циљ
\[
G_0 \leftarrow A_1, A_2, \dots, A_n.
\]
\textbf{Један SLD корак} бира један потциљ $A_i$, проналази клаузу $H :- B_1, \dots, B_m \in P$ и \emph{MGU} $\theta$ за $A_i$ и $H$, и формира нови циљ
\[
G' \leftarrow (A_1, \dots, A_{i-1}, B_1, \dots, B_m, A_{i+1}, \dots, A_n)\theta,
\]
што записујемо као $G \Rightarrow_{\theta} G'$.
\emph{SLD} је \textbf{селективна} (бира се један потциљ), \textbf{линеарна} (деривација прати једну путању) и важи за \textbf{дефинитне} (коначне) клаузе. Одатле и назив \emph{SLD резолуција} (\emph{Selective Linear Definite clause resolution}). \cite{janii_2004_matematika}.

\paragraph{Деривација и одговор.}
Низ
\[
G_0 \Rightarrow_{\theta_1} G_1 \Rightarrow_{\theta_2} \cdots \Rightarrow_{\theta_k} G_k
\]
је успешан ако је $G_k=\Box$ (празан циљ). Тада је одговор супституција $\theta = \theta_1 \circ \cdots \circ \theta_k$. \cite{janii_2004_matematika}.

\paragraph{Својства.}
SLD је коректна (сваки изведен одговор је логичка последица) и потпуна за дефинитне програме (ако је циљ последица, постоји успешна SLD деривација).

\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Карактеристика} & \textbf{Унификација} & \textbf{SLD резолуција} \\
\midrule
Циљ & Решава $t_1 = t_2$ над термовима & Трансформише циљеве коришћењем клаузa \\
Резултат & Супституција (MGU ако постоји) & Празан циљ и композиција супституција \\
Природа & Локална операција (један корак) & Глобални процес (цео доказ) \\
\bottomrule
\end{tabular}
}
\caption{Поређење унификације и SLD резолуције.}
\label{table:unification_vs_sld}
\end{table}


\subsection{Индуктивно логичко програмирање (ILP)}
У индуктивном логичком програмирању циљ је да се, на основу примера и позадинског знања, индукцијом добије \emph{хипотеза} (скуп правила) која објашњава посматране податке.

\paragraph{Формална поставка.}
Дато $E^+$ (позитивни примери), $E^-$ (негативни примери) и $BK$ (позадинско знање), пронаћи хипотезу $H$ (скуп дефинитних Хорнових правила) такву да
\[
BK \cup H \models E^+ 
\quad\text{и}\quad
BK \cup H \not\models E^-.
\]
У пракси се уз то дефинишу \emph{језичка ограничења} (bias) и мере квалитета (нпр. покривеност, тачност).

\paragraph{Напомена (distillation).}
У \emph{teacher-based} дестилацији прво се обучи „учитељ“ (нпр. \emph{ML} модел); његове предикције ($y_{\text{pred}}$) се користе за формирање $E^+$/$E^-$, а ILP потом индучује правила која имитирају понашање учитеља.


\subsection{Модели машинског учења}

У овом потпоглављу ће бити разматране неке од најпопуларнијих модела машинског учења заснованих на стаблима: стабла одлучивања, случајне шуме и XGBoost.

\subsubsection{Стабла одлучивања}

Стабла одлучивања представљају једноставан, али моћан модел за класификацију, као и за регресију. Идеја је да се скуп примера рекурзивно дели „одозго-надоле“, тако да се бира обележје за корен, потом и за свако разгранавање, све док се не стигне до листова који носе класу.

Циљ је да се добије што једноставније стабло које се добро \textit{генерализује} и ван података намењених за тестирање.

Кључни корак је избор „најбољег“ обележја у свакој тачки. У \textit{ID3} приступу то се ради по \textit{информационом добитку}, односно мери се смањење неизвесности (ентропије) о класи након гранања по обележју, па се бира онај са највећим добитком. Поред ентропије, могу се користити и друге мере као што је \textit{гини индекс}.

Ова одозго-надоле индукција стабала одлуке (\textit{TDIDT}) третира учење као тражење образаца у примерима, независно од редоследа, и фаворизује једноставна стабла која боље хватају стварну структуру задатка у односу на сложена која само „објашњавају“ тренинг.

Емпиријски, \textit{ID3} често даје проста стабла која тачно класификују велики део невиђених објеката, чак и на доменима са много обележја. \cite{quinlan1996induction}

\subsubsection{Случајне (насумичне) шуме}

Случајне шуме (често у литератури као \textit{рендом форест}) је ансамбл метода великог броја стабала одлуке.

\paragraph{Како ради:}
\begin{itemize}
  \item свако стабло се тренира на насумично изабраном узорку података са враћањем (\textit{bootstrap} узорак), тако да сваки модел добија свој скуп примера, често са понављањима;  \item у сваком чвору се за дељење бира најбоље обележје \emph{из насумично изабраног подскупа} обележја
  \item предвиђање се добија гласањем (класификација) или просеком (регресија).
\end{itemize}

Овакво насумично ограничавање скупа обележја уводи независност међу стаблима, снижава корелацију и тако, уз снажна појединачна стабла, драматично смањује варијансу модела.

\paragraph{Практичне предности:}
\begin{itemize}
  \item унутрашња процена грешке преко \textit{out-of-bag} примера, који настају јер око трећина података не улази у бутстреп узорак и зато могу да служе као мини тест сет за процену стабала;
  \item природна мера важности обележја (нпр. процена се добија тако што се насумично пермутују вредности неког обележја, па се мери колико то умањује тачност модела);
  \item робусност и мала осетљивост на подешавања хиперпараметара.
\end{itemize}

Теоријски, општа грешка се стабилизује како број стабала расте и зависи од „јачине“ стабала и њихове међусобне корелације. У пракси, метода често даје врхунске резултате на разним доменима. \cite{breiman2001random}

\subsubsection{XGBoost}

XGBoost је систем за градијентно бустовање стабала: додаје се много плитких стабала једних за другим, при чему свако ново стабло исправља остатке претходних.

\paragraph{Кључне идеје:}
\begin{itemize}
  \item регулисана функција циља са L1/L2 казнама над листовима, што значи да се сложеност модела директно контролише кажњавањем превеликог броја или превеликих вредности у листовима, па се тако смањује преобучавање;
  \item другоредна (Њутнова) апроксимација за ефикасан избор подела: уместо да користи само први извод (градијент), алгоритам користи и други извод (Хесијан) функције губитка, што омогућава брже и прецизније одређивање где поделити чвор;
  \item \textit{sparsity-aware} учење, тј. уграђена подршка за ретке податке и недостајуће вредности: алгоритам паметно бира гране за „празне“ уносе тако да се информација ипак максимално искористи;
  \item \textit{weighted quantile sketch}, алгоритам за брзо и прецизно генерисање кандидата за сплитове и када постоје тежински пондерисани примери, што значајно убрзава тренинг.
\end{itemize}

\paragraph{Системске оптимизације:}
\begin{itemize}
  \item колонијски подсемплинг и кеш-свесни блокови: уместо да користи све особине одједном, XGBoost може да узима само подскуп колона ради ефикасности, а податке организује тако да максимално искористи кеш меморију процесора;
  \item паралелизам и дистрибуирани рад: грађење стабала може се обављати паралелно по чворовима и по машинама, што омогућава велико убрзање и тренинг на кластерима;
  \item \textit{out-of-core} рачун, односно могућност тренинга директно са диска када скупови података не могу да стану у RAM меморију, при чему се користе оптимизовани алгоритми за читање и писање података.
\end{itemize}

Захваљујући овим техникама, XGBoost скалира на милијарде примера и често постиже \textit{state-of-the-art} резултате у пракси. \cite{chen2016xgboost}

\subsection{Дестилација знања}

\textbf{Дестилација знања} је техника преношења знања из великог, сложеног модела (учитеља) у мањи, ефикаснији модел (ученика/студента). Циљ је да се сачува што више перформанси учитеља, али уз мању сложеност и брже извршавање.

\paragraph{Како ради:}
\begin{itemize}
  \item учитељ се прво обучи на оригиналном скупу података;
  \item затим се генеришу излази учитеља за исти скуп или проширени скуп података;
  \item ученик се обучава да имитира излаз учитеља, понекад уз додатну обуку на оригиналним ознакама.
\end{itemize}

\paragraph{Примена:}
Дестилација је посебно корисна када је потребно имплементирати моделе на уређајима са ограниченим ресурсима (нпр. мобилни телефони, уграђени системи) или када је брзина извршавања критична. Често се користи у дубоком учењу, али је применљива и на друге типове модела. Поред тога, дестилација може помоћи у интерпретабилности сложених модела, јер ученик често има једноставнију структуру која је лакша за разумевање. \cite{hinton2015distilling}

\subsection{Врсте знања и шеме тренинга}

\paragraph{Врсте знања.}
Пренос знања у дестилацији може се класификовати према типу информација које се преносе:
\begin{itemize}
  \item \textbf{\emph{Response-based}:} Пренос логита или вероватноћа које учитељ генерише за сваки узорак. Овај приступ је најједноставнији и најчешће коришћен.
  \item \textbf{\emph{Feature-based}:} Пренос средњих репрезентација (активација) из скривених слојева учитеља.\\
  Овај приступ омогућава ученику да учи богатије репрезентације.
  \item \textbf{\emph{Relation-based}:} Пренос односа између узорака или њихових репрезентација. Овај приступ се фокусира на структуру података коју учитељ открива.
\end{itemize}

\paragraph{Шеме тренинга.}
Дестилација знања може се организовати у различитим шемама:
\begin{itemize}
  \item \textbf{\emph{Offline}:} Учитељ се прво обучи, а затим се његово знање преноси на ученика. Ова шема је најчешћа и погодна за статичне скупове података.
  \item \textbf{\emph{Online}:} Учитељ и ученик се обучавају истовремено, често у међусобној интеракцији или као ансамбл модела.
  \item \textbf{Self-\emph{distillation}:} Један модел служи као учитељ и ученик, где се знање преноси из дубљих слојева у плиће.
\end{itemize}

\paragraph{Архитектуре и алгоритми.}
У овом раду се разматра \textbf{\emph{offline, response-based}} дестилација, где је учитељ (ансамбл) стабала, а ученик логички модел. Циљ је постићи висок фиделитет према учитељу уз добру генерализацију и контролисану сложеност скупа правила.

\paragraph{Изазови.}
Главни изазови у дестилацији знања укључују:
\begin{itemize}
  \item Квалитет извора знања (учитеља).
  \item \emph{Data-free} дестилација (када оригинални подаци нису доступни).
  \item Дестилација од више учитеља.
\end{itemize} \cite{gou2021knowledge}